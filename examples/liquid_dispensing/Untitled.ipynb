{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ac63957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ngboost import NGBRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8456b600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thf 100 : 39\n",
      "thf 500 : 67\n",
      "hep 100 : 69\n",
      "ace 100 : 48\n"
     ]
    }
   ],
   "source": [
    "# load in datasets\n",
    "\n",
    "param_names = ['src_flow', 'dst_flow', 'airgap', 'post_airgap', 'extra_volume', 'src_equib', 'dst_equib']\n",
    "obj_names = ['error', 'stdev']\n",
    "\n",
    "col_names = param_names+obj_names\n",
    "\n",
    "df_thf_100 = pd.read_csv(\n",
    "    '../../../olympus/src/olympus/datasets/dataset_liquid_thf_100/data.csv', names=col_names\n",
    ")\n",
    "\n",
    "df_thf_500 = pd.read_csv(\n",
    "    '../../../olympus/src/olympus/datasets/dataset_liquid_thf_500/data.csv', names=col_names\n",
    ")\n",
    "\n",
    "df_hep_100 = pd.read_csv(\n",
    "    '../../../olympus/src/olympus/datasets/dataset_liquid_hep_100/data.csv', names=col_names\n",
    ")\n",
    "\n",
    "df_ace_100 = pd.read_csv(\n",
    "    '../../../olympus/src/olympus/datasets/dataset_liquid_ace_100/data.csv', names=col_names\n",
    ")\n",
    "\n",
    "print(f'thf 100 : {df_thf_100.shape[0]}')\n",
    "print(f'thf 500 : {df_thf_500.shape[0]}')\n",
    "print(f'hep 100 : {df_hep_100.shape[0]}')\n",
    "print(f'ace 100 : {df_ace_100.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "30abca2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 7) (69, 2)\n",
      "(51, 7) (51, 2)\n",
      "(18, 7) (18, 2)\n"
     ]
    }
   ],
   "source": [
    "X = df_hep_100[param_names].values\n",
    "y = df_hep_100[obj_names].values\n",
    "\n",
    "train_frac = 0.75\n",
    "num_train = int(train_frac*y.shape[0])\n",
    "indices = np.arange(y.shape[0])\n",
    "np.random.seed(100701)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices = indices[:num_train]\n",
    "test_indices = indices[num_train:]\n",
    "\n",
    "train_X = X[train_indices, :]\n",
    "train_y = y[train_indices, :]\n",
    "\n",
    "test_X = X[test_indices, :]\n",
    "test_y = y[test_indices, :]\n",
    "\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print(train_X.shape, train_y.shape)\n",
    "print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f00f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngboost hyperparams\n",
    "n_estimators=1500\n",
    "lr=0.001\n",
    "tol=1e-4\n",
    "patience=100\n",
    "\n",
    "model = [ \n",
    "    NGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=lr,\n",
    "        tol=tol\n",
    "    ) for _ in range(y.shape[1])\n",
    "]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ce21cab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=-1.7183 val_loss=0.0000 scale=2.0000 norm=1.6187\n",
      "[iter 100] loss=-2.1501 val_loss=0.0000 scale=2.0000 norm=0.8853\n",
      "[iter 200] loss=-2.2565 val_loss=0.0000 scale=2.0000 norm=0.8412\n",
      "[iter 300] loss=-2.3501 val_loss=0.0000 scale=2.0000 norm=0.8360\n",
      "[iter 400] loss=-2.4393 val_loss=0.0000 scale=2.0000 norm=0.8404\n",
      "[iter 500] loss=-2.5262 val_loss=0.0000 scale=2.0000 norm=0.8446\n",
      "[iter 600] loss=-2.6115 val_loss=0.0000 scale=2.0000 norm=0.8459\n",
      "[iter 700] loss=-2.6956 val_loss=0.0000 scale=2.0000 norm=0.8448\n",
      "[iter 800] loss=-2.7782 val_loss=0.0000 scale=2.0000 norm=0.8415\n",
      "[iter 900] loss=-2.8596 val_loss=0.0000 scale=2.0000 norm=0.8365\n",
      "[iter 1000] loss=-2.9414 val_loss=0.0000 scale=2.0000 norm=0.8330\n",
      "[iter 1100] loss=-3.0217 val_loss=0.0000 scale=2.0000 norm=0.8276\n",
      "[iter 1200] loss=-3.1008 val_loss=0.0000 scale=2.0000 norm=0.8210\n",
      "[iter 1300] loss=-3.1787 val_loss=0.0000 scale=2.0000 norm=0.8133\n",
      "[iter 1400] loss=-3.2577 val_loss=0.0000 scale=2.0000 norm=0.8092\n",
      "[iter 0] loss=-3.6436 val_loss=0.0000 scale=1.0000 norm=0.4767\n",
      "[iter 100] loss=-3.7362 val_loss=0.0000 scale=1.0000 norm=0.3985\n",
      "[iter 200] loss=-3.8136 val_loss=0.0000 scale=1.0000 norm=0.3462\n",
      "[iter 300] loss=-3.8696 val_loss=0.0000 scale=1.0000 norm=0.3199\n",
      "[iter 400] loss=-3.9185 val_loss=0.0000 scale=1.0000 norm=0.3038\n",
      "[iter 500] loss=-3.9623 val_loss=0.0000 scale=1.0000 norm=0.2952\n",
      "[iter 600] loss=-4.0079 val_loss=0.0000 scale=1.0000 norm=0.2930\n",
      "[iter 700] loss=-4.0521 val_loss=0.0000 scale=1.0000 norm=0.2966\n",
      "[iter 800] loss=-4.0889 val_loss=0.0000 scale=1.0000 norm=0.3026\n",
      "[iter 900] loss=-4.1275 val_loss=0.0000 scale=1.0000 norm=0.3067\n",
      "[iter 1000] loss=-4.1695 val_loss=0.0000 scale=1.0000 norm=0.3078\n",
      "[iter 1100] loss=-4.2231 val_loss=0.0000 scale=2.0000 norm=0.6242\n",
      "[iter 1200] loss=-4.2871 val_loss=0.0000 scale=1.0000 norm=0.3165\n",
      "[iter 1300] loss=-4.3382 val_loss=0.0000 scale=1.0000 norm=0.3231\n",
      "[iter 1400] loss=-4.3853 val_loss=0.0000 scale=1.0000 norm=0.3249\n"
     ]
    }
   ],
   "source": [
    "for ix in range(len(model)):\n",
    "    model[ix].verbose = True\n",
    "    model[ix].fit(train_X, train_y[:, ix])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50159f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 2) (51, 2)\n"
     ]
    }
   ],
   "source": [
    "y_train_mu, y_train_std = [], []\n",
    "y_test_mu, y_test_std = [], []\n",
    "for m in model:\n",
    "    y_dists = m.pred_dist(test_X)\n",
    "    y_test_mu.append(y_dists.loc)\n",
    "    y_test_std.append(np.sqrt(y_dists.var))\n",
    "    \n",
    "    y_dists = m.pred_dist(train_X)\n",
    "    y_train_mu.append(y_dists.loc)\n",
    "    y_train_std.append(np.sqrt(y_dists.var))\n",
    "    \n",
    "y_train_mu = np.stack(y_train_mu, axis=0).T\n",
    "y_train_std = np.stack(y_train_std, axis=0).T\n",
    "\n",
    "y_test_mu = np.stack(y_test_mu, axis=0).T\n",
    "y_test_std = np.stack(y_test_std, axis=0).T\n",
    "\n",
    "print(y_train_mu.shape, y_train_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12450777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9778807752734834 0.7978432217888721\n",
      "-0.06314631302617757 -0.08000482473061843\n"
     ]
    }
   ],
   "source": [
    "r2_e_train = r2_score(train_y[:, 0], y_train_mu[:, 0])\n",
    "r2_s_train = r2_score(train_y[:, 1], y_train_mu[:, 1])\n",
    "\n",
    "r2_e_test = r2_score(test_y[:, 0], y_test_mu[:, 0])\n",
    "r2_s_test = r2_score(test_y[:, 1], y_test_mu[:, 1])\n",
    "\n",
    "print(r2_e_train, r2_s_train)\n",
    "print(r2_e_test, r2_s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c998593c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas",
   "language": "python",
   "name": "atlas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
